{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T16:12:14.772835Z",
     "iopub.status.busy": "2020-09-15T16:12:14.772579Z",
     "iopub.status.idle": "2020-09-15T16:12:14.775936Z",
     "shell.execute_reply": "2020-09-15T16:12:14.775396Z",
     "shell.execute_reply.started": "2020-09-15T16:12:14.772800Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('shallow-trt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T16:12:16.208613Z",
     "iopub.status.busy": "2020-09-15T16:12:16.208349Z",
     "iopub.status.idle": "2020-09-15T16:12:16.432881Z",
     "shell.execute_reply": "2020-09-15T16:12:16.432280Z",
     "shell.execute_reply.started": "2020-09-15T16:12:16.208578Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T16:12:16.955597Z",
     "iopub.status.busy": "2020-09-15T16:12:16.953645Z",
     "iopub.status.idle": "2020-09-15T16:12:18.373518Z",
     "shell.execute_reply": "2020-09-15T16:12:18.372775Z",
     "shell.execute_reply.started": "2020-09-15T16:12:16.955559Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from itertools import chain\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T16:12:21.341059Z",
     "iopub.status.busy": "2020-09-15T16:12:21.340786Z",
     "iopub.status.idle": "2020-09-15T16:12:21.374586Z",
     "shell.execute_reply": "2020-09-15T16:12:21.374039Z",
     "shell.execute_reply.started": "2020-09-15T16:12:21.341022Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "def GiB(val): return val * 1 << 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T16:12:23.026493Z",
     "iopub.status.busy": "2020-09-15T16:12:23.026222Z",
     "iopub.status.idle": "2020-09-15T16:12:23.058078Z",
     "shell.execute_reply": "2020-09-15T16:12:23.057473Z",
     "shell.execute_reply.started": "2020-09-15T16:12:23.026458Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_onnx(onnx_file_path, explicit_batch=None, max_batch_size=1):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)\n",
    "    trt.init_libnvinfer_plugins(TRT_LOGGER, '') \n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "\n",
    "    if explicit_batch is not None:\n",
    "        EXPLICIT_BATCH = explicit_batch << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "        network = builder.create_network(EXPLICIT_BATCH)\n",
    "    else:\n",
    "        network = builder.create_network()\n",
    "        builder.max_batch_size = max_batch_size\n",
    "\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)    \n",
    "    logger = logging.getLogger('onnx_parser')\n",
    "\n",
    "    with open(onnx_file_path, 'rb') as model:\n",
    "        if not parser.parse(model.read()):\n",
    "            for error in range(parser.num_errors):\n",
    "                logger.debug(parser.get_error(error))\n",
    "\n",
    "    logger.debug(f'NETWORK PARSE: {len(network)}')\n",
    "    return builder, network, TRT_LOGGER\n",
    "\n",
    "def build_trt_engine(builder, network, mode='fp32', max_workspace_size_gb=1):\n",
    "    builder.fp16_mode = True if mode == 'fp16' else False\n",
    "    builder.int8_mode = True if mode == 'int8' else False\n",
    "    \n",
    "    builder.max_workspace_size = GiB(max_workspace_size_gb)\n",
    "    engine = builder.build_cuda_engine(network)\n",
    "    return engine\n",
    "    \n",
    "def save_engine(engine, engine_dest_path):\n",
    "    buf = engine.serialize()\n",
    "    with open(engine_dest_path, 'wb') as f:\n",
    "        f.write(buf)\n",
    "\n",
    "def load_engine(trt_runtime, engine_path):\n",
    "    with open(engine_path, 'rb') as f:\n",
    "        engine_data = f.read()\n",
    "    engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "    return engine\n",
    "\n",
    "def init_trt():\n",
    "    trt_logger = trt.Logger(trt.Logger.INFO)\n",
    "    trt.init_libnvinfer_plugins(trt_logger, '')\n",
    "    runtime = trt.Runtime(trt_logger)\n",
    "    return trt_logger, runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HostDeviceMem:\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.h = host_mem\n",
    "        self.d = device_mem\n",
    "\n",
    "    def __str__(self):   return \"Host:\\n\" + str(self.h) + \"\\nDevice:\\n\" + str(self.d)\n",
    "    def __repr__(self):  return self.__str__()\n",
    "    \n",
    "    def htod(self, stream):\n",
    "        cuda.memcpy_htod_async(self.d, self.h, stream)\n",
    "        #stream.synchronize()\n",
    "        \n",
    "    def dtoh(self, stream):\n",
    "        cuda.memcpy_dtoh_async(self.h, self.d, stream)\n",
    "        #stream.synchronize()\n",
    "        \n",
    "def allocate_buffers(engine, dtypes=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        engine (trt.ICudaEngine): TensorRT engine\n",
    "    Returns:\n",
    "        inputs [HostDeviceMem]: engine input memory\n",
    "        outputs [HostDeviceMem]: engine output memory\n",
    "        bindings [int]: buffer to device bindings\n",
    "        stream (cuda.Stream): cuda stream for engine inference synchronization\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    bindings = []\n",
    "    stream = cuda.Stream()\n",
    "    for i, binding in enumerate(engine):\n",
    "        size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "        if dtypes is not None: \n",
    "            dtype = dtypes[i]\n",
    "        else:\n",
    "            dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "        \n",
    "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "        bindings.append(int(device_mem))\n",
    "        \n",
    "        if engine.binding_is_input(binding):\n",
    "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "        else:\n",
    "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    return inputs, outputs, bindings, stream\n",
    "\n",
    "\n",
    "def do_inference(context, bindings, inputs, outputs, stream, batch_size=1, explicit_batch=False):\n",
    "    [inp.htod(stream) for inp in inputs]\n",
    "    context_exec = context.execute_async_v2 if explicit_batch else context.execute_async\n",
    "    context_exec(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)\n",
    "    [out.dtoh(stream) for out in outputs]\n",
    "    stream.synchronize()\n",
    "    return [out.h for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T16:12:23.782915Z",
     "iopub.status.busy": "2020-09-15T16:12:23.782683Z",
     "iopub.status.idle": "2020-09-15T16:12:23.816515Z",
     "shell.execute_reply": "2020-09-15T16:12:23.815972Z",
     "shell.execute_reply.started": "2020-09-15T16:12:23.782889Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseEngine:\n",
    "    \"\"\"Base engine class\n",
    "        Creates TRT engine, allocates memory\n",
    "    \"\"\"    \n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        config: Dict\n",
    "        {\n",
    "            'engine':'path/to/engine.trt',\n",
    "   optional 'dtypes':[trt.DataType.BOOL, trt.DataType.FLOAT, trt.DataType.HALF, trt.DataType.INT32, trt.DataType.INT8]\n",
    "   \n",
    "       }\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.trt_logger, self.runtime = init_trt()\n",
    "        self.engine = load_engine(self.runtime, self.config['engine'])\n",
    "        self.context = self.engine.create_execution_context()\n",
    "        dtypes = self.config.get('dtypes', None)\n",
    "        self.inputs, self.outputs, self.bindings, self.stream = allocate_buffers(self.engine, dtypes=dtypes)\n",
    "    \n",
    "    def sync(self): self.stream.synchronize()\n",
    "\n",
    "    def info(self):\n",
    "        print([self.engine.get_binding_name(i) for i in range(self.engine.num_bindings)])\n",
    "        print([self.engine.get_binding_shape(i) for i in range(self.engine.num_bindings)])\n",
    "        print([self.engine.get_binding_dtype(i) for i in range(self.engine.num_bindings)])\n",
    "        \n",
    "    def execute(self, bindings, sync=True):\n",
    "        self.context.execute_async(bindings=bindings, stream_handle=self.stream.handle)\n",
    "        if sync: self.sync()\n",
    "    \n",
    "    def load_input(self, inp):\n",
    "        \"\"\"\n",
    "        inp is 4D tensor or list of 3D tensors\n",
    "        \"\"\"\n",
    "        #assert isinstance(inp, list), 'input must be a list'\n",
    "        \n",
    "        for i, inputs in zip(inp, self.inputs):\n",
    "            np.copyto(inputs.h, i.ravel())\n",
    "    \n",
    "    def dtoh(self, sync=False):\n",
    "        [out.dtoh(self.stream) for out in self.outputs]\n",
    "        if sync: self.sync()\n",
    "    \n",
    "    def htod(self, sync=False):\n",
    "        [inp.htod(self.stream) for inp in self.inputs]\n",
    "        if sync: self.sync()\n",
    "        \n",
    "    def _start(self):\n",
    "        self.dtoh(sync=True)\n",
    "        self.execute(self.bindings)\n",
    "        self.htod(sync=True)\n",
    "        return [out.h for out in self.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-14T11:21:22.931846Z",
     "iopub.status.busy": "2020-09-14T11:21:22.931562Z",
     "iopub.status.idle": "2020-09-14T11:21:22.934651Z",
     "shell.execute_reply": "2020-09-14T11:21:22.934111Z",
     "shell.execute_reply.started": "2020-09-14T11:21:22.931809Z"
    }
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "def prepare_image(img_in, size):\n",
    "    img = cv2.resize(img_in,size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.transpose(2, 0, 1) # to CHW\n",
    "    return img/128 - 1 \n",
    "\n",
    "def load_test_image(path, size):\n",
    "    img = cv2.imread(path)\n",
    "    img_prep = prepare_image(img, size)\n",
    "    return img_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'engine':'/tmp/test.trt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = BaseEngine(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e._start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
